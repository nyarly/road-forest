Client error exceptions
  40x -> per code exception classes, include Response content

Other concerns:
Content type handling (iow: RDF<->text format)
Authentication
Authorization
Content encoding (gzip, compress)
Charsets
Languages
Exception handling

HTML related:
  Method coercion (POST that means DELETE/PUT)
  Params -> graph
  Form rendering
  Limited fan-out of received data - e.g. file uploads to forms

Cacheing - last_modified, expires, etag(+ W/)

property delete

property replace

repo autovacuum

collect vocabs used to generate a graph - build curies for representations that work that way

BGP queries should be solveable *across* resources - currently all patterns get
a :context variable applied that all have to match, but it seems reasonable
that multiple resources might participate in a solution.

HTTP behaviors:
Handling status codes -
  Empty vs. full responses (200 v 204)
  3xx and Location following
  4xx - sometimes correctable, otherwise...
  5xx



*** API challenges ***

Client behavior should get packed up in a tidy bunch of chains and blocks, but
if there's an error, Ruby's default exceptions aren't helpful.  NullObjects of
some kind?

Remove the _:local context - it doesn't make sense on the GM. Writes to a GM
should come from 3 places:

 * A GraphFocus, that has an implicit context to write to.
 * Raw #insert by client code - in which case, vaya con Dios
 * #insert_document, which has an explicit context to write to.

GM's should also accept non-ResourceQuery|Patterns. Simple to RQ|P.from(q|p),
with infered contexts.

Infered contexts raises this interesting point: every pattern potentially has 6
contexts to consider as credible:

 * Its context
 * Its subject
 * Its object
 * Contexts mentioned in its query
 * Subjects mentioned in its query
 * Objects mentioned in its query

(Not every pattern will have all 6) (Also - more than one of any may result in
an empty result - a Query with two contexts I *think* means "statements must
have this context and that context" which is impossible.)

That said, these resources might then form the basis of a credence review


*** Pure Mad Science ***

Omniscient test server.

Basically: RemoteHost collects the requests that get made and records them.
Play against server, and then "flatten" resulting meta-graph. TestServer simply
replies to everything with flattened graph - possibly changing state (graph) on
PUT/POST/DELETE.

Two sets of test files:

client -> server requests, the responses of which can be tested and recorded

server -> client responses, used as fixtures for client tests - right things
displayed / correct POSTs made.


Single Graph Update
 -- reflection indicates this should be removed. It's not really RESTful, and
 the use case (the converse of front loading) actually doesn't seem to make
 sense. "Batch" or "transaction" updates really should be collected into a new
 resource, if it makes sense. If it doesn't you probably don't really want that
 kind of update anyway


Statistical Front Loading
based on human definitions of resource graphs, and
emperical collection of client behavior (e.g. GET resourceB, Referer:
resourceA, (X-)Triggering-Property: propC), determine properties to front-load
into requests for resourceA to reduce the likelihood of subsequent request for
B. Contributing factors include the size of the extra data, impact on cacheing,
actual impact on subsequent requests (since propC shadows some non-negative
number of other properties we need about resourceB.)

Consider case of an list of users page - client wants names and roles for all
users. So UserList -> User1,User2,User3 etc because of foaf:name and also
authn:role. Once we front load both foaf:name and authn:name, UserList ->
User17, because that's the particular user we want. But: foaf:name makes not
impact by itself (except to change the triggering property), and both aren't an
absolute impact. On the other extreme, front-loading everything from User into
UserList probably stops requests for User17, but the network transfer is
greater as a result.

Certainly, there's a tendancy for everything to be front loaded, and as clients
change we might need to experimentally roll back a front-loading to see if that
triggers more requests.
